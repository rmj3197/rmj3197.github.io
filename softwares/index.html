<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<!-- _pages/publications.md --><!-- <p>An up-to-date list is available on <a href="https://scholar.google.com/citations?user=qNk6tgcAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>.</p> --><html><body>
<div class="softwares">
  <h2 class="year">2024</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 abbr"></div>

  <!-- Entry bib key -->
  <div id="saraceno2024goodnessoffit" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Goodness-of-Fit and Clustering of Spherical Data: the QuadratiK package in R and Python</div>
    <!-- Author -->
    <div class="author">
      

      Giovanni Saraceno, <em>Marianthi Markatou</em>, Raktim Mukhopadhyay, and Mojgan Golzy</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>We introduce the QuadratiK package that incorporates innovative data analysis methodologies. The presented software, implemented in both R and Python, offers a comprehensive set of goodness-of-fit tests and clustering techniques using kernel-based quadratic distances, thereby bridging the gap between the statistical and machine learning literatures. Our software implements one, two and k-sample tests for goodness of fit, providing an efficient and mathematically sound way to assess the fit of probability distributions. Expanded capabilities of our software include supporting tests for uniformity on the d-dimensional Sphere based on Poisson kernel densities, and algorithms for generating random samples from Poisson kernel densities. Particularly noteworthy is the incorporation of a unique clustering algorithm specifically tailored for spherical data that leverages a mixture of Poisson-kernel-based densities on the sphere. Alongside this, our software includes additional graphical functions, aiding the users in validating, as well as visualizing and representing clustering results. This enhances interpretability and usability of the analysis. In summary, our R and Python packages serve as a powerful suite of tools, offering researchers and practitioners the means to delve deeper into their data, draw robust inference, and conduct potentially impactful analyses and inference across a wide array of disciplines.</p>
    </div>
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 abbr"></div>

  <!-- Entry bib key -->
  <div id="RJ-2023-027" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">Likelihood Ratio Test-Based Drug Safety Assessment using R Package pvLRT</div>
    <!-- Author -->
    <div class="author">
      

      Saptarshi Chakraborty, <em>Marianthi Markatou</em>, and Robert Ball</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>The R Journal</em>, 2023
    </div>
    <div class="periodical">
      https://doi.org/10.32614/RJ-2023-027
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Medical product safety continues to be a key concern of the twenty-first century. Several spontaneous adverse events reporting databases established across the world continuously collect and archive adverse events data on various medical products. Determining signals of disproportional reporting (SDR) of product/adverse event pairs from these large-scale databases require the use of principled statistical techniques. Likelihood ratio test (LRT)-based approaches are particularly noteworthy in this context as they permit objective SDR detection without requiring ad hoc thresholds. However, their implementation is non-trivial due to analytical complexities, which necessitate the use of computation-heavy methods. Here we introduce R package pvLRT which implements a suite of LRT approaches, along with various post-processing and graphical summary functions, to facilitate simplified use of the methodologies. Detailed examples are provided to illustrate the package through analyses of three real product safety datasets obtained from publicly available FDA FAERS and VAERS databases.</p>
    </div>
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 abbr"></div>

  <!-- Entry bib key -->
  <div id="JSSv083i13" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">kamila: Clustering Mixed-Type Data in R and Hadoop</div>
    <!-- Author -->
    <div class="author">
      

      Alexander H. Foss, and <em>Marianthi Markatou</em>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>Journal of Statistical Software</em>, 2018
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://www.jstatsoft.org/index.php/jss/article/view/v083i13" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>In this paper we discuss the challenge of equitably combining continuous (quantitative) and categorical (qualitative) variables for the purpose of cluster analysis. Existing techniques require strong parametric assumptions, or difficult-to-specify tuning parameters. We describe the kamila package, which includes a weighted k-means approach to clustering mixed-type data, a method for estimating weights for mixed-type data (ModhaSpangler weighting), and an additional semiparametric method recently proposed in the literature (KAMILA). We include a discussion of strategies for estimating the number of clusters in the data, and describe the implementation of one such method in the current R package. Background and usage of these clustering methods are presented. We then show how the KAMILA algorithm can be adapted to a map-reduce framework, and implement the resulting algorithm using Hadoop for clustering very large mixed-type data sets.</p>
    </div>
  </div>
</div>
</li></ol>

  <h2 class="year">2011</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 abbr"></div>

  <!-- Entry bib key -->
  <div id="cite-key" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">A Platform for Processing Expression of Short Time Series (PESTS)</div>
    <!-- Author -->
    <div class="author">
      

      Anshu Sinha, and <em>Marianthi Markatou</em>
</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>BMC Bioinformatics</em>, 2011
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://doi.org/10.1186/1471-2105-12-13" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Time course microarray profiles examine the expression of genes over a time domain. They are necessary in order to determine the complete set of genes that are dynamically expressed under given conditions, and to determine the interaction between these genes. Because of cost and resource issues, most time series datasets contain less than 9 points and there are few tools available geared towards the analysis of this type of data.</p>
    </div>
  </div>
</div>
</li></ol>


</div>
</body></html>
